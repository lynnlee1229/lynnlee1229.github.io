<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Lynn's Site"><meta property="og:type" content="article"><meta property="og:image" content="/img/ram.png"><meta property="twitter:image" content="/img/ram.png"><meta name=title content="【八股】mysql-事务"><meta property="og:title" content="【八股】mysql-事务"><meta property="twitter:title" content="【八股】mysql-事务"><meta name=description content="李柞霖，武汉大学硕士研究生, 开源爱好者 | 这里是 李柞霖 的个人主页"><meta property="og:description" content="李柞霖，武汉大学硕士研究生, 开源爱好者 | 这里是 李柞霖 的个人主页"><meta property="twitter:description" content="李柞霖，武汉大学硕士研究生, 开源爱好者 | 这里是 李柞霖 的个人主页"><meta property="twitter:card" content="summary"><meta name=keyword content="李柞霖, Li Zuolin, Lynn Lee, 李柞霖的主页"><link rel="shortcut icon" href=/image/favicon.ico><title>【八股】mysql-事务 | 李柞霖的博客</title><link rel=canonical href=/post/mysql%E5%85%AB%E8%82%A1-%E4%BA%8B%E5%8A%A1/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.css><link href=https://cdn.jsdelivr.net/gh/FortAwesome/Font-Awesome@5.15.1/css/all.css rel=stylesheet type=text/css><script src=/js/jquery.min.js></script>
<script src=/js/bootstrap.min.js></script>
<script src=/js/hux-blog.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=/>Lynn's Site</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/research>research</a></li><li><a href=/categories/technology>technology</a></li><li><a href=/archive/>ARCHIVE</a></li><li><a href=/about/>ABOUT</a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(/img/ram.png)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/mysql%E5%85%AB%E8%82%A1 title=mysql八股>mysql八股</a></div><h1>【八股】mysql-事务</h1><h2 class=subheading></h2><span class=meta>Posted by
Lynn
on
Tuesday, May 16, 2023</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h1 id=什么是数据库事务>什么是数据库事务</h1><p>事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。</p><h1 id=事务的特性>事务的特性</h1><p>事务看起来感觉简单，但是要实现事务必须要遵守 4 个特性，分别如下：</p><ul><li><strong>原子性（Atomicity）</strong>：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样</li><li><strong>一致性（Consistency）</strong>：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。</li><li><strong>隔离性（Isolation）</strong>：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。</li><li><strong>持久性（Durability）</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li></ul><p>InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p><ul><li>持久性是通过 redo log （重做日志）来保证的；</li><li>原子性是通过 undo log（回滚日志） 来保证的；</li><li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li><li>一致性则是通过持久性+原子性+隔离性来保证；</li></ul><h1 id=并行事务会出现的问题>并行事务会出现的问题</h1><h2 id=脏读>脏读</h2><p><strong>如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。</strong></p><p>事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据</p><h2 id=不可重复读>不可重复读</h2><p><strong>在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。</strong></p><p>事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。</p><h2 id=幻读>幻读</h2><p><strong>在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。</strong></p><p>不可重复读侧重于修改，幻读侧重于新增或删除（多了或少量行），脏读是一个事务回滚影响另外一个事务。</p><p>严重程度：脏读>不可重复读>幻读</p><h1 id=事务的隔离级别>事务的隔离级别</h1><p>SQL 标准提出了四种隔离级别来规避会出现的问题，隔离级别越高，性能效率就越低，这四个隔离级别如下：</p><ul><li><strong>读未提交（*read uncommitted*）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到；</li><li><strong>读提交（*read committed*）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到；</li><li><strong>可重复读（*repeatable read*）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>；</li><li><strong>串行化（*serializable* ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；</li></ul><p>针对不同的隔离级别，并发事务时可能发生的现象也会不同。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/4e98ea2e60923b969790898565b4d643.png alt=图片></p><p>MySQL 在「可重复读」隔离级别下，可以很大程度上避免幻读现象的发生（注意是很大程度避免，并不是彻底避免），所以 MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能。</p><ul><li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li><li>针对<strong>当前读</strong>（select &mldr; for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，因为当执行 select &mldr; for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</li></ul><p>这四种隔离级别具体是如何实现的呢？</p><ul><li>对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；</li><li>对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；</li><li>对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 <strong>Read View来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View</strong>。</li></ul><p>注意，执行「开始事务」命令，并不意味着启动了事务。在 MySQL 有两种开启事务的命令，分别是：</p><ul><li>第一种：begin/start transaction 命令；</li><li>第二种：start transaction with consistent snapshot 命令；</li></ul><p>这两种开启事务的命令，事务的启动时机是不同的：</p><ul><li>执行了 begin/start transaction 命令后，并不代表事务启动了。只有在执行这个命令后，执行了增删查改操作的 SQL 语句，才是事务真正启动的时机；</li><li>执行了 start transaction with consistent snapshot 命令，就会马上启动事务。</li></ul><h2 id=mysql可重复读隔离级别完全解决幻读了吗>MYSQL可重复读隔离级别，完全解决幻读了吗？</h2><ul><li>快照读如何解决幻读</li></ul><p>可重复读隔离级是由 MVCC（多版本并发控制）实现的，实现的方式是开始事务后（执行 begin 语句后），在执行第一个查询语句后，会创建一个 Read View，<strong>后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的</strong>，即使中途有其他事务插入了新纪录，是查询不出来这条数据的，所以就很好了避免幻读问题。</p><ul><li>当前读如何解决幻读</li></ul><p>MySQL 里除了普通查询是快照读，其他都是<strong>当前读</strong>，比如 update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。</p><p>这很好理解，假设你要 update 一个记录，另一个事务已经 delete 这条记录并且提交事务了，这样不是会产生冲突吗，所以 update 的时候肯定要知道最新的数据。</p><p>另外，<code>select ... for update</code> 这种查询语句是当前读，每次执行的时候都是读取最新的数据</p><p><strong>Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了间隙锁</strong>。</p><p>假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/gap%E9%94%81.drawio.png alt=img></p><ul><li>幻读被完全解决了吗</li></ul><p><strong>第一个发生幻读现象的场景</strong></p><p>还是以这张表作为例子：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/7f9df142b3594daeaaca495abb7133f5-20230309222119359.png alt=img></p><p>事务 A 执行查询 id = 5 的记录，此时表中是没有该记录的，所以查询不出来。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#ff79c6>#</span> 事务 A
</span></span><span style=display:flex><span>mysql<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>begin</span>;
</span></span><span style=display:flex><span>Query OK, <span style=color:#bd93f9>0</span> <span style=color:#ff79c6>rows</span> affected (<span style=color:#bd93f9>0</span>.<span style=color:#bd93f9>00</span> sec)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mysql<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>select</span> <span style=color:#ff79c6>*</span> <span style=color:#ff79c6>from</span> t_stu <span style=color:#ff79c6>where</span> id <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>5</span>;
</span></span><span style=display:flex><span>Empty <span style=color:#ff79c6>set</span> (<span style=color:#bd93f9>0</span>.<span style=color:#bd93f9>01</span> sec)
</span></span></code></pre></div><p>然后事务 B 插入一条 id = 5 的记录，并且提交了事务。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#ff79c6>#</span> 事务 B
</span></span><span style=display:flex><span>mysql<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>begin</span>;
</span></span><span style=display:flex><span>Query OK, <span style=color:#bd93f9>0</span> <span style=color:#ff79c6>rows</span> affected (<span style=color:#bd93f9>0</span>.<span style=color:#bd93f9>00</span> sec)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mysql<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>insert</span> <span style=color:#ff79c6>into</span> t_stu <span style=color:#ff79c6>values</span>(<span style=color:#bd93f9>5</span>, <span style=color:#f1fa8c>&#39;小美&#39;</span>, <span style=color:#bd93f9>18</span>);
</span></span><span style=display:flex><span>Query OK, <span style=color:#bd93f9>1</span> <span style=color:#ff79c6>row</span> affected (<span style=color:#bd93f9>0</span>.<span style=color:#bd93f9>00</span> sec)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mysql<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>commit</span>;
</span></span><span style=display:flex><span>Query OK, <span style=color:#bd93f9>0</span> <span style=color:#ff79c6>rows</span> affected (<span style=color:#bd93f9>0</span>.<span style=color:#bd93f9>00</span> sec)
</span></span></code></pre></div><p>此时，<strong>事务 A 更新 id = 5 这条记录，对没错，事务 A 看不到 id = 5 这条记录，但是他去更新了这条记录，这场景确实很违和，然后再次查询 id = 5 的记录，事务 A 就能看到事务 B 插入的纪录了，幻读就是发生在这种违和的场景</strong>。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#ff79c6>#</span> 事务 A
</span></span><span style=display:flex><span>mysql<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>update</span> t_stu <span style=color:#ff79c6>set</span> name <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#39;小林coding&#39;</span> <span style=color:#ff79c6>where</span> id <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>5</span>;
</span></span><span style=display:flex><span>Query OK, <span style=color:#bd93f9>1</span> <span style=color:#ff79c6>row</span> affected (<span style=color:#bd93f9>0</span>.<span style=color:#bd93f9>01</span> sec)
</span></span><span style=display:flex><span><span style=color:#ff79c6>Rows</span> matched: <span style=color:#bd93f9>1</span>  Changed: <span style=color:#bd93f9>1</span>  Warnings: <span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mysql<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>select</span> <span style=color:#ff79c6>*</span> <span style=color:#ff79c6>from</span> t_stu <span style=color:#ff79c6>where</span> id <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>5</span>;
</span></span><span style=display:flex><span><span style=color:#ff79c6>+</span><span style=color:#6272a4>----+--------------+------+
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>|</span> id <span style=color:#ff79c6>|</span> name         <span style=color:#ff79c6>|</span> age  <span style=color:#ff79c6>|</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>+</span><span style=color:#6272a4>----+--------------+------+
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>|</span>  <span style=color:#bd93f9>5</span> <span style=color:#ff79c6>|</span> 小林coding   <span style=color:#ff79c6>|</span>   <span style=color:#bd93f9>18</span> <span style=color:#ff79c6>|</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>+</span><span style=color:#6272a4>----+--------------+------+
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#bd93f9>1</span> <span style=color:#ff79c6>row</span> <span style=color:#ff79c6>in</span> <span style=color:#ff79c6>set</span> (<span style=color:#bd93f9>0</span>.<span style=color:#bd93f9>00</span> sec)
</span></span></code></pre></div><p>整个发生幻读的时序图如下：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E5%B9%BB%E8%AF%BB%E5%8F%91%E7%94%9F.drawio.png alt=img></p><p>在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id = 5 的记录并提交。接着，事务 A 对 id = 5 这条记录进行了更新操作，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。</p><p>因为这种特殊现象的存在，所以我们认为 <strong>MySQL Innodb 中的 MVCC 并不能完全避免幻读现象</strong>。</p><p><strong>第二个发生幻读现象的场景</strong></p><p>除了上面这一种场景会发生幻读现象之外，还有下面这个场景也会发生幻读现象。</p><ul><li>T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id > 100 得到了 3 条记录。</li><li>T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；</li><li>T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。</li></ul><p><strong>要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select &mldr; for update 这类当前读的语句</strong>，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录</p><h1 id=mysql事务日志>MYSQL事务日志</h1><p>innodb 事务日志包括 redo log 和 undo log。</p><p>undo log 指事务开始之前，在操作任何数据之前，首先将需操作的数据备份到一个地方。</p><p>redo log 指事务中操作的任何数据，将最新的数据备份到一个地方。</p><p>事务日志的目的：实例或者介质失败，事务日志文件就能派上用场。</p><ul><li>redo log</li></ul><p>redo log 不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 redo 中。具体的落盘策略可以进行配置 。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启 MySQL 服务的时候，根据 redo log 进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。<strong>RedoLog 是为了实现事务的持久性而出现的产物</strong>。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/image-20210822181340692.png alt=image-20210822181340692></p><ul><li>Undo log</li></ul><p>undo log 用来回滚行记录到某个版本。事务未提交之前，Undo 保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读。<strong>是为了实现事务的原子性而出现的产物</strong>,在 MySQL innodb 存储引擎中用来实现多版本并发控制。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/image-20210822181416382.png alt=image-20210822181416382></p><h1 id=mysql-binlog>MYSQL binlog</h1><p>MySQL的 binlog 是记录所有数据库表结构变更（例如 CREATE、ALTER TABLE）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志。binlog 不会记录 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改，但你可以通过查询通用日志来查看 MySQL 执行过的所有语句。</p><p>MySQL binlog 以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的二进制日志是事务安全型的。binlog 的主要目的是复制和恢复。</p><p>binlog 有三种格式，各有优缺点：</p><ul><li><strong>statement：</strong> 基于 SQL 语句的模式，某些语句和函数如 UUID, LOAD DATA INFILE 等在复制过程可能导致数据不一致甚至出错。</li><li><strong>row：</strong> 基于行的模式，记录的是行的变化，很安全。但是 binlog 会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大。</li><li><strong>mixed：</strong> 混合模式，根据语句来选用是 statement 还是 row 模式。</li></ul><h1 id=mysql-日志undo-logredo-logbinlog-各有什么用>MYSQL 日志：undo log、redo log、binlog 各有什么用？</h1><h2 id=为什么需要undo-log>为什么需要undo log</h2><p>一个事务在执行过程中，在还没有提交事务之前，如果 MySQL 发生了崩溃，要怎么回滚到事务之前的数据呢？</p><p>如果我们每次在事务执行过程中，都记录下回滚时需要的信息到一个日志里，那么在事务执行中途发生了 MySQL 崩溃后，就不用担心无法回滚到事务之前的数据，我们可以通过这个日志回滚到事务之前的数据。</p><p>实现这一机制就是 undo log（回滚日志），它保证了事务的原子性</p><p>undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E5%9B%9E%E6%BB%9A%E4%BA%8B%E5%8A%A1.png alt=回滚事务></p><p>在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。</p><p>一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：</p><ul><li>通过 trx_id 可以知道该记录是被哪个事务修改的；</li><li>通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为<strong>版本链</strong></li></ul><p>因此，undo log 两大作用：</p><ul><li><strong>实现事务回滚，保障事务的原子性</strong>。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。</li><li><strong>实现 MVCC（多版本并发控制）关键因素之一</strong>。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。</li></ul><h2 id=为什么需要buffer-pool>为什么需要Buffer Pool</h2><p>要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。那修改完这条记录是选择直接写回到磁盘，还是选择缓存起来呢？当然是缓存起来好，这样下次有查询语句命中了这条记录，直接读取缓存中的记录，就不需要从磁盘获取数据了。</p><p>为此，Innodb 存储引擎设计了一个<strong>缓冲池（Buffer Pool）</strong>，来提高数据库的读写性能。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E7%BC%93%E5%86%B2%E6%B1%A0.drawio.png alt="Buffer Poo"></p><p>有了 Buffer Pool 后：</p><ul><li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li><li>当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为<strong>脏页</strong>（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。</li></ul><p><strong>Buffer Pool 缓存什么？</strong></p><p>InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。</p><p>在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的<code>16KB</code>的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页</strong>。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。</p><p>所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系。</p><p>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/bufferpool%e5%86%85%e5%ae%b9.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt=img></p><blockquote><p>Undo 页是记录什么？</p></blockquote><p>开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。</p><blockquote><p>查询一条记录，就只需要缓冲一条记录吗？</p></blockquote><p>不是的。</p><p>当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，将页加载到 Buffer Pool 后，再通过页里的「页目录」去定位到某条具体的记录。</p><h2 id=为什么需要redo-log>为什么需要redo log</h2><p>Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。</p><p>为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，<strong>这个时候更新就算完成了</strong>。</p><p>后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 <strong>WAL （Write-Ahead Logging）技术</strong>。</p><p><strong>WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上</strong>。</p><p>过程如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/wal.png alt=img></p><blockquote><p>什么是 redo log？</p></blockquote><p>redo log 是物理日志，记录了某个数据页做了什么修改，比如<strong>对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新</strong>，每当执行一个事务就会产生这样的一条或者多条物理日志。</p><p>在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。</p><p>当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。</p><blockquote><p>被修改 Undo 页面，需要记录对应 redo log 吗？</p></blockquote><p>需要的。</p><p>开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。</p><p>不过，<strong>在内存修改该 Undo 页面后，需要记录对应的 redo log</strong>。</p><blockquote><p>redo log 和 undo log 区别在哪？</p></blockquote><p>这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：</p><ul><li>redo log 记录了此次事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值；</li><li>undo log 记录了此次事务「<strong>开始前</strong>」的数据状态，记录的是更新<strong>之前</strong>的值；</li></ul><p>事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%e4%ba%8b%e5%8a%a1%e6%81%a2%e5%a4%8d.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt=事务恢复></p><p>所以有了 redo log，再通过 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失，这个能力称为 <strong>crash-safe</strong>（崩溃恢复）。可以看出来， <strong>redo log 保证了事务四大特性中的持久性</strong>。</p><blockquote><p>redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？</p></blockquote><p>写入 redo log 的方式使用了追加操作， 所以磁盘操作是<strong>顺序写</strong>，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是<strong>随机写</strong>。</p><p>磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。</p><p>针对「顺序写」为什么比「随机写」更快这个问题，可以比喻为你有一个本子，按照顺序一页一页写肯定比写一个字都要找到对应页写快得多。</p><p>可以说这是 WAL 技术的另外一个优点：<strong>MySQL 的写操作从磁盘的「随机写」变成了「顺序写」</strong>，提升语句的执行性能。这是因为 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上 。</p><p>至此， 针对为什么需要 redo log 这个问题我们有两个答案：</p><ul><li><strong>实现事务的持久性，让 MySQL 有 crash-safe 的能力</strong>，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；</li><li><strong>将写操作从「随机写」变成了「顺序写」</strong>，提升 MySQL 写入磁盘的性能。</li></ul><blockquote><p>产生的 redo log 是直接写入磁盘的吗？</p></blockquote><p>不是的。</p><p>实际上， 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I/O 操作，而且磁盘的运行速度远慢于内存。</p><p>所以，redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/redologbuf.webp alt=事务恢复></p><p>redo log buffer 默认大小 16 MB，可以通过 <code>innodb_log_Buffer_size</code> 参数动态的调整大小，增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能。</p><p><strong>redo log 什么时候刷盘？</strong></p><p>缓存在 redo log buffer 里的 redo log 还是在内存中，它什么时候刷新到磁盘？</p><p>主要有下面几个时机：</p><ul><li>MySQL 正常关闭时；</li><li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li><li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li><li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。</li></ul><blockquote><p>innodb_flush_log_at_trx_commit 参数控制的是什么？</p></blockquote><p>单独执行一个更新语句的时候，InnoDB 引擎会自己启动一个事务，在执行更新语句的过程中，生成的 redo log 先写入到 redo log buffer 中，然后等事务提交的时候，再将缓存在 redo log buffer 中的 redo log 按组的方式「顺序写」到磁盘。</p><p>上面这种 redo log 刷盘时机是在事务提交的时候，这个默认的行为。</p><p>除此之外，InnoDB 还提供了另外两种策略，由参数 <code>innodb_flush_log_at_trx_commit</code> 参数控制，可取的值有：0、1、2，默认值为 1，这三个值分别代表的策略如下：</p><ul><li>当设置该<strong>参数为 0 时</strong>，表示每次事务提交时 ，还是<strong>将 redo log 留在 redo log buffer 中</strong> ，该模式下在事务提交时不会主动触发写入磁盘的操作。</li><li>当设置该<strong>参数为 1 时</strong>，表示每次事务提交时，都<strong>将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘</strong>，这样可以保证 MySQL 异常重启之后数据不会丢失。</li><li>当设置该<strong>参数为 2 时</strong>，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log <strong>写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘</strong>，因为操作系统的文件系统中有个 Page Cache，Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。</li></ul><p>我画了一个图，方便大家理解：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/innodb_flush_log_at_trx_commit.drawio.png alt=img></p><blockquote><p>innodb_flush_log_at_trx_commit 为 0 和 2 的时候，什么时候才将 redo log 写入磁盘？</p></blockquote><p>InnoDB 的后台线程每隔 1 秒：</p><ul><li>针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 <code>write()</code> 写到操作系统的 Page Cache，然后调用 <code>fsync()</code> 持久化到磁盘。<strong>所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失</strong>;</li><li>针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。<strong>所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失</strong>。</li></ul><p>加入了后台现线程后，innodb_flush_log_at_trx_commit 的刷盘时机如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/innodb_flush_log_at_trx_commit2.drawio.png alt=img></p><blockquote><p>这三个参数的应用场景是什么？</p></blockquote><p>这三个参数的数据安全性和写入性能的比较如下：</p><ul><li>数据安全性：参数 1 > 参数 2 > 参数 0</li><li>写入性能：参数 0 > 参数 2> 参数 1</li></ul><p>所以，数据安全性和写入性能是熊掌不可得兼的，<strong>要不追求数据安全性，牺牲性能；要不追求性能，牺牲数据安全性</strong>。</p><ul><li>在一些对数据安全性要求比较高的场景中，显然 <code>innodb_flush_log_at_trx_commit</code> 参数需要设置为 1。</li><li>在一些可以容忍数据库崩溃时丢失 1s 数据的场景中，我们可以将该值设置为 0，这样可以明显地减少日志同步到磁盘的 I/O 操作。</li><li>安全性和性能折中的方案就是参数 2，虽然参数 2 没有参数 0 的性能高，但是数据安全性方面比参数 0 强，因为参数 2 只要操作系统不宕机，即使数据库崩溃了，也不会丢失数据，同时性能方便比参数 1 高。</li></ul><p><strong>redo log 文件写满了怎么办？</strong></p><p>默认情况下， InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：<code>ib_logfile0</code> 和 <code>ib_logfile1</code> 。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E9%87%8D%E5%81%9A%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%BB%84.drawio.png alt=重做日志文件组></p><p>在重做日志组中，每个 redo log File 的大小是固定且一致的，假设每个 redo log File 设置的上限是 1 GB，那么总共就可以记录 2GB 的操作。</p><p>重做日志文件组是以<strong>循环写</strong>的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形。</p><p>所以 InnoDB 存储引擎会先写 ib_logfile0 文件，当 ib_logfile0 文件被写满的时候，会切换至 ib_logfile1 文件，当 ib_logfile1 文件也被写满时，会切换回 ib_logfile0 文件。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E9%87%8D%E5%81%9A%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%BB%84%E5%86%99%E5%85%A5%E8%BF%87%E7%A8%8B.drawio.png alt=重做日志文件组写入过程></p><p>我们知道 redo log 是为了防止 Buffer Pool 中的脏页丢失而设计的，那么如果随着系统运行，Buffer Pool 的脏页刷新到了磁盘中，那么 redo log 对应的记录也就没用了，这时候我们擦除这些旧记录，以腾出空间记录新的更新操作。</p><p>redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置，如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/checkpoint.png alt=img></p><p>图中的：</p><ul><li>write pos 和 checkpoint 的移动都是顺时针方向；</li><li>write pos ～ checkpoint 之间的部分（图中的红色部分），用来记录新的更新操作；</li><li>check point ～ write pos 之间的部分（图中蓝色部分）：待落盘的脏数据页记录；</li></ul><p>如果 write pos 追上了 checkpoint，就意味着 <strong>redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞</strong>（<em>因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要</em>），此时<strong>会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）</strong>，然后 MySQL 恢复正常运行，继续执行新的更新操作。</p><p>所以，一次 checkpoint 的过程就是脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程。</p><h2 id=为什么需要binlog>为什么需要binlog</h2><p>前面介绍的 undo log 和 redo log 这两个日志都是 Innodb 存储引擎生成的。</p><p>MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。</p><p>binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。</p><blockquote><p>为什么有了 binlog， 还要有 redo log？</p></blockquote><p>这个问题跟 MySQL 的时间线有关系。</p><p>最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。</p><p>而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。</p><p><strong>redo log 和 binlog 有什么区别？</strong></p><p>这两个日志有四个区别。</p><p><em>1、适用对象不同：</em></p><ul><li>binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；</li><li>redo log 是 Innodb 存储引擎实现的日志；</li></ul><p><em>2、文件格式不同：</em></p><ul><li>binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：<ul><li>STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；</li><li>ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；</li><li>MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</li></ul></li><li>redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；</li></ul><p><em>3、写入方式不同：</em></p><ul><li>binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。</li><li>redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。</li></ul><p><em>4、用途不同：</em></p><ul><li>binlog 用于备份恢复、主从复制；</li><li>redo log 用于掉电等故障恢复。</li></ul><blockquote><p>如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？</p></blockquote><p>不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。</p><p>因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。</p><p>binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据。</p><p><strong>主从复制是怎么实现？</strong></p><p>MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。</p><p>这个过程一般是<strong>异步</strong>的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B.drawio.png alt="MySQL 主从复制过程"></p><p>MySQL 集群的主从复制过程梳理成 3 个阶段：</p><ul><li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li><li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li><li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li></ul><p>具体详细过程如下：</p><ul><li>MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</li><li>从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。</li><li>从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。</li></ul><p>在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84.drawio.png alt="MySQL 主从架构"></p><blockquote><p>从库是不是越多越好？</p></blockquote><p>不是的。</p><p>因为从库数量增加，从库连接上来的 I/O 线程也比较多，<strong>主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽</strong>。</p><p>所以在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。</p><blockquote><p>MySQL 主从复制还有哪些模型？</p></blockquote><p>主要有三种：</p><ul><li><strong>同步复制</strong>：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。</li><li><strong>异步复制</strong>（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。</li><li><strong>半同步复制</strong>：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种<strong>半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险</strong>。</li></ul><p><strong>binlog什么时候刷盘</strong></p><p>事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p><p>一个事务的 binlog 是不能被拆开的，因此无论这个事务有多大（比如有很多条语句），也要保证一次性写入。这是因为有一个线程只能同时有一个事务在执行的设定，所以每当执行一个 begin/start transaction 的时候，就会默认提交上一个事务，这样如果一个事务的 binlog 被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。</p><p>MySQL 给每个线程分配了一片内存用于缓冲 binlog ，该内存叫 binlog cache，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。</p><blockquote><p>什么时候 binlog cache 会写到 binlog 文件？</p></blockquote><p>在事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 文件中，并清空 binlog cache。如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/binlogcache.drawio.png alt="binlog cach"></p><p>虽然每个线程有自己 binlog cache，但是最终都写到同一个 binlog 文件：</p><ul><li>图中的 write，指的就是指把日志写入到 binlog 文件，但是并没有把数据持久化到磁盘，因为数据还缓存在文件系统的 page cache 里，write 的写入速度还是比较快的，因为不涉及磁盘 I/O。</li><li>图中的 fsync，才是将数据持久化到磁盘的操作，这里就会涉及磁盘 I/O，所以频繁的 fsync 会导致磁盘的 I/O 升高。</li></ul><p>MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：</p><ul><li>sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；</li><li>sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；</li><li>sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li></ul><p>在MySQL中系统默认的设置是 sync_binlog = 0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦主机发生异常重启，还没持久化到磁盘的数据就会丢失。</p><p>而当 sync_binlog 设置为 1 的时候，是最安全但是性能损耗最大的设置。因为当设置为 1 的时候，即使主机发生异常重启，最多丢失一个事务的 binlog，而已经持久化到磁盘的数据就不会有影响，不过就是对写入性能影响太大。</p><p>如果能容少量事务的 binlog 日志丢失的风险，为了提高写入的性能，一般会 sync_binlog 设置为 100~1000 中的某个数值。</p><blockquote><p>三个日志讲完了，至此我们可以先小结下，update 语句的执行过程。</p></blockquote><p>当优化器分析出成本最小的执行计划后，执行器就按照执行计划开始进行更新操作。</p><p>具体更新一条记录 <code>UPDATE t_user SET name = 'xiaolin' WHERE id = 1;</code> 的流程如下:</p><ol><li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：<ul><li>如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li><li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li></ul></li><li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ul><li>如果一样的话就不进行后续更新流程；</li><li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li></ul></li><li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</li><li>InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 <strong>WAL 技术</strong>，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</li><li>至此，一条记录更新完了。</li><li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li><li>事务提交，剩下的就是「两阶段提交」的事情了，接下来就讲这个。</li></ol><h2 id=为什么需要两阶段提交>为什么需要两阶段提交</h2><p>事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。</p><p>举个例子，假设 id = 1 这行数据的字段 name 的值原本是 &lsquo;jay&rsquo;，然后执行 <code>UPDATE t_user SET name = 'xiaolin' WHERE id = 1;</code> 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况：</p><ul><li><strong>如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入</strong>。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id = 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性；</li><li><strong>如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入</strong>。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id = 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性；</li></ul><p>可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。</p><p><strong>MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决</strong>，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。</p><p><strong>两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」</strong>，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。</p><p>举个拳击比赛的例子，两位拳击手（参与者）开始比赛之前，裁判（协调者）会在中间确认两位拳击手的状态，类似于问你准备好了吗？</p><ul><li><strong>准备阶段</strong>：裁判（协调者）会依次询问两位拳击手（参与者）是否准备好了，然后拳击手听到后做出应答，如果觉得自己准备好了，就会跟裁判说准备好了；如果没有自己还没有准备好（比如拳套还没有带好），就会跟裁判说还没准备好。</li><li><strong>提交阶段</strong>：如果两位拳击手（参与者）都回答准备好了，裁判（协调者）宣布比赛正式开始，两位拳击手就可以直接开打；如果任何一位拳击手（参与者）回答没有准备好，裁判（协调者）会宣布比赛暂停，对应事务中的回滚操作。</li></ul><p><strong>过程</strong></p><p>在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了<strong>内部 XA 事务</strong>（是的，也有外部 XA 事务，跟本文不太相关，我就不介绍了），内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。</p><p>当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，<strong>分两阶段来完成 XA 事务的提交</strong>，如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.drawio.png alt=两阶段提交></p><p>从图中可看出，事务的提交过程有两个阶段，就是<strong>将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog</strong>，具体如下：</p><ul><li><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；</li><li><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；</li></ul><p><strong>异常重启会出现什么现象</strong></p><p>我们来看看在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象？下图中有时刻 A 和时刻 B 都有可能发生崩溃：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%e4%b8%a4%e9%98%b6%e6%ae%b5%e6%8f%90%e4%ba%a4%e5%b4%a9%e6%ba%83%e7%82%b9.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="时刻 A 与时刻 B"></p><p>不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，<strong>此时的 redo log 都处于 prepare 状态</strong>。</p><p>在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：</p><ul><li><strong>如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务</strong>。对应时刻 A 崩溃恢复的情况。</li><li><strong>如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务</strong>。对应时刻 B 崩溃恢复的情况。</li></ul><p>可以看到，<strong>对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID</strong>，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。</p><p>所以说，<strong>两阶段提交是以 binlog 写成功为事务提交成功的标识</strong>，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。</p><blockquote><p>处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?</p></blockquote><p>binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。</p><p>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。</p><blockquote><p>事务没提交的时候，redo log 会被持久化到磁盘吗？</p></blockquote><p>会的。</p><p>事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。</p><p>也就是说，<strong>事务没提交的时候，redo log 也是可能被持久化到磁盘的</strong>。</p><p>有的同学可能会问，如果 mysql 崩溃了，还没提交事务的 redo log 已经被持久化磁盘了，mysql 重启后，数据不就不一致了？</p><p>放心，这种情况 mysql 重启会进行回滚操作，因为事务没提交的时候，binlog 是还没持久化到磁盘的。</p><p>所以， redo log 可以在事务没提交之前持久化到磁盘，但是 binlog 必须在事务提交之后，才可以持久化到磁盘。</p><p><strong>两阶段提交有什么问题</strong></p><p>两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：</p><ul><li><strong>磁盘 I/O 次数高</strong>：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</li><li><strong>锁竞争激烈</strong>：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。</li></ul><blockquote><p>为什么两阶段提交的磁盘 I/O 次数会很高？</p></blockquote><p>binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一般我们为了避免日志丢失的风险，会将这两个参数设置为 1：</p><ul><li>当 sync_binlog = 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘；</li><li>当 innodb_flush_log_at_trx_commit = 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘；</li></ul><p>可以看到，如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会<strong>至少调用 2 次刷盘操作</strong>，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。</p><blockquote><p>为什么锁竞争激烈？</p></blockquote><p>在早期的 MySQL 版本中，通过使用 prepare_commit_mutex 锁来保证事务提交的顺序，在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁，下个事务才可以继续进行 prepare 操作。</p><p>通过加锁虽然完美地解决了顺序一致性的问题，但在并发量较大的时候，就会导致对锁的争用，性能不佳。</p><p><strong>组提交</strong></p><p><strong>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</strong>，如果说 10 个事务依次排队刷盘的时间成本是 10，那么将这 10 个事务一次性一起刷盘的时间成本则近似于 1。</p><p>引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：</p><ul><li><strong>flush 阶段</strong>：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；</li><li><strong>sync 阶段</strong>：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；</li><li><strong>commit 阶段</strong>：各个事务按顺序做 InnoDB commit 操作；</li></ul><p>上面的<strong>每个阶段都有一个队列</strong>，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/commit_4.png alt=每个阶段都有一个队列></p><p>对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，<strong>锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率</strong>。</p><blockquote><p>有 binlog 组提交，那有 redo log 组提交吗？</p></blockquote><p>这个要看 MySQL 版本，MySQL 5.6 没有 redo log 组提交，MySQL 5.7 有 redo log 组提交。</p><p>在 MySQL 5.6 的组提交逻辑中，每个事务各自执行 prepare 阶段，也就是各自将 redo log 刷盘，这样就没办法对 redo log 进行组提交。</p><p>所以在 MySQL 5.7 版本中，做了个改进，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段，也就是说 prepare 阶段融合在了 flush 阶段。</p><p>这个优化是将 redo log 的刷盘延迟到了 flush 阶段之中，sync 阶段之前。通过延迟写 redo log 的方式，为 redolog 做了一次组写入，这样 binlog 和 redo log 都进行了优化。</p><p>接下来介绍每个阶段的过程，注意下面的过程针对的是“双 1” 配置（sync_binlog 和 innodb_flush_log_at_trx_commit 都配置为 1）。</p><blockquote><p>flush 阶段</p></blockquote><p>第一个事务会成为 flush 阶段的 Leader，此时后面到来的事务都是 Follower ：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E7%BB%84%E6%8F%90%E4%BA%A41.png alt=img></p><p>接着，获取队列中的事务组，由绿色事务组的 Leader 对 redo log 做一次 write + fsync，即一次将同组事务的 redolog 刷盘：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E7%BB%84%E6%8F%90%E4%BA%A42.png alt=img></p><p>完成了 prepare 阶段后，将绿色这一组事务执行过程中产生的 binlog 写入 binlog 文件（调用 write，不会调用 fsync，所以不会刷盘，binlog 缓存在操作系统的文件系统中）。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/write_binlog.png alt=img></p><p>从上面这个过程，可以知道 flush 阶段队列的作用是<strong>用于支撑 redo log 的组提交</strong>。</p><p>如果在这一步完成后数据库崩溃，由于 binlog 中没有该组事务的记录，所以 MySQL 会在重启后回滚该组事务。</p><blockquote><p>sync 阶段</p></blockquote><p>绿色这一组事务的 binlog 写入到 binlog 文件后，并不会马上执行刷盘的操作，而是<strong>会等待一段时间</strong>，这个等待的时长由 <code>Binlog_group_commit_sync_delay</code> 参数控制，<strong>目的是为了组合更多事务的 binlog，然后再一起刷盘</strong>，如下过程：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E7%BB%84%E6%8F%90%E4%BA%A44.png alt=img></p><p>不过，在等待的过程中，如果事务的数量提前达到了 <code>Binlog_group_commit_sync_no_delay_count</code> 参数设置的值，就不用继续等待了，就马上将 binlog 刷盘，如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E7%BB%84%E6%8F%90%E4%BA%A45.png alt=img></p><p>从上面的过程，可以知道 sync 阶段队列的作用是<strong>用于支持 binlog 的组提交</strong>。</p><p>如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：</p><ul><li><code>binlog_group_commit_sync_delay= N</code>，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。</li><li><code>binlog_group_commit_sync_no_delay_count = N</code>，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。</li></ul><p>如果在这一步完成后数据库崩溃，由于 binlog 中已经有了事务记录，MySQL会在重启后通过 redo log 刷盘的数据继续进行事务的提交。</p><blockquote><p>commit 阶段</p></blockquote><p>最后进入 commit 阶段，调用引擎的提交事务接口，将 redo log 状态设置为 commit。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E7%BB%84%E6%8F%90%E4%BA%A46.png alt=img></p><p>commit 阶段队列的作用是承接 sync 阶段的事务，完成最后的引擎提交，使得 sync 可以尽早的处理下一组事务，最大化组提交的效率</p><h2 id=mysql-io很高的优化方法>MYSQL I/O很高的优化方法</h2><p>现在我们知道事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I/O 很高的现象，我们可以通过控制以下参数，来 “延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I/O 的频率：</p><ul><li>设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。</li><li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。</li><li>将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据</li></ul><h2 id=buffer-pool相关>Buffer Pool相关</h2><p><strong>bp有多大</strong></p><p>Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 <code>128MB</code> 。</p><p>可以通过调整 <code>innodb_buffer_pool_size</code> 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%。</p><p><strong>bp缓存什么</strong></p><p>InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。</p><p>在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的<code>16KB</code>的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页</strong>。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。</p><p>所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系。</p><p>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/bufferpool%e5%86%85%e5%ae%b9.drawio.png alt=img></p><p>为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个<strong>控制块</strong>，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。</p><p>控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页，如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E7%BC%93%E5%AD%98%E9%A1%B5.drawio.png alt=img></p><p>上图中控制块和缓存页之间灰色部分称为碎片空间。</p><blockquote><p>为什么会有碎片空间呢？</p></blockquote><p>你想想啊，每一个控制块都对应一个缓存页，那在分配足够多的控制块和缓存页后，可能剩余的那点儿空间不够一对控制块和缓存页的大小，自然就用不到喽，这个用不到的那点儿内存空间就被称为碎片了。</p><p>当然，如果你把 Buffer Pool 的大小设置的刚刚好的话，也可能不会产生碎片。</p><blockquote><p>查询一条记录，就只需要缓冲一条记录吗？</p></blockquote><p>不是的。</p><p>当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。</p><p><strong>如何管理bp</strong></p><p><strong>1、如何管理空闲页</strong></p><p>Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。</p><p>那当我们从磁盘读取数据的时候，总不能通过遍历这一片连续的内存空间来找到空闲的缓存页吧，这样效率太低了。</p><p>所以，为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 <strong>Free 链表</strong>（空闲链表）。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/freelist.drawio.png alt=img></p><p>Free 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。</p><p>Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。</p><p>有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。</p><p><strong>2、如何管理脏页？</strong></p><p>设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为<strong>脏页</strong>，然后再由后台线程将脏页写入到磁盘。</p><p>那为了能快速知道哪些缓存页是脏的，于是就设计出 <strong>Flush 链表</strong>，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/Flush.drawio.png alt=img></p><p>有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。</p><p><strong>3、如何提高缓存命中率？</strong></p><p>Buffer Pool 的大小是有限的，对于一些频繁访问的数据我们希望可以一直留在 Buffer Pool 中，而一些很少访问的数据希望可以在某些时机可以淘汰掉，从而保证 Buffer Pool 不会因为满了而导致无法再缓存新的数据，同时还能保证常用数据留在 Buffer Pool 中。</p><p>要实现这个，最容易想到的就是 LRU（Least recently used）算法。</p><p>该算法的思路是，链表头部的节点是最近使用的，而链表末尾的节点是最久没被使用的。那么，当空间不够了，就淘汰最久没被使用的节点，从而腾出空间。</p><p>简单的 LRU 算法的实现思路是这样的：</p><ul><li>当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。</li><li>当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。</li></ul><p>比如下图，假设 LRU 链表长度为 5，LRU 链表从左到右有 1，2，3，4，5 的页。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lru.png alt=img></p><p>如果访问了 3 号的页，因为 3 号页在 Buffer Pool 里，所以把 3 号页移动到头部即可。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lru2.png alt=img></p><p>而如果接下来，访问了 8 号页，因为 8 号页不在 Buffer Pool 里，所以需要先淘汰末尾的 5 号页，然后再将 8 号页加入到头部。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lru3.png alt=img></p><p>到这里我们可以知道，Buffer Pool 里有三种页和链表来管理数据。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/bufferpoll_page.png alt=img></p><p>图中：</p><ul><li>Free Page（空闲页），表示此页未被使用，位于 Free 链表；</li><li>Clean Page（干净页），表示此页已被使用，但是页面未发生修改，位于LRU 链表。</li><li>Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 LRU 链表和 Flush 链表。</li></ul><p>简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题：</p><ul><li>预读失效；</li><li>Buffer Pool 污染；</li></ul><blockquote><p>什么是预读失效？</p></blockquote><p>先来说说 MySQL 的预读机制。程序是有空间局部性的，靠近当前被访问数据的数据，在未来很大概率会被访问到。</p><p>所以，MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。</p><p>但是可能这些<strong>被提前加载进来的数据页，并没有被访问</strong>，相当于这个预读是白做了，这个就是<strong>预读失效</strong>。</p><p>如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。</p><p>如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。</p><blockquote><p>怎么解决预读失效而导致缓存命中率降低的问题？</p></blockquote><p>我们不能因为害怕预读失效，而将预读机制去掉，大部分情况下，局部性原理还是成立的。</p><p>要避免预读失效带来影响，最好就是<strong>让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长</strong>。</p><p>那到底怎么才能避免呢？</p><p>MySQL 是这样做的，它改进了 LRU 算法，将 LRU 划分了 2 个区域：<strong>old 区域 和 young 区域</strong>。</p><p>young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/young%252Bold-20230518224416064.png alt=img></p><p>old 区域占整个 LRU 链表长度的比例可以通过 <code>innodb_old_blocks_pct</code> 参数来设置，默认是 37，代表整个 LRU 链表中 young 区域与 old 区域比例是 63:37。</p><p><strong>划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部</strong>。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。</p><p>接下来，给大家举个例子。</p><p>假设有一个长度为 10 的 LRU 链表，其中 young 区域占比 70 %，old 区域占比 30 %。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/lrutwo.drawio.png alt=img></p><p>现在有个编号为 20 的页被预读了，这个页只会被插入到 old 区域头部，而 old 区域末尾的页（10号）会被淘汰掉。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lrutwo2.png alt=img></p><p>如果 20 号页一直不会被访问，它也没有占用到 young 区域的位置，而且还会比 young 区域的数据更早被淘汰出去。</p><p>如果 20 号页被预读后，立刻被访问了，那么就会将它插入到 young 区域的头部，young 区域末尾的页（7号），会被挤到 old 区域，作为 old 区域的头部，这个过程并不会有页被淘汰。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/lrutwo3.png alt=img></p><p>虽然通过划分 old 区域 和 young 区域避免了预读失效带来的影响，但是还有个问题无法解决，那就是 Buffer Pool 污染的问题。</p><blockquote><p>什么是 Buffer Pool 污染？</p></blockquote><p>当某一个 SQL 语句<strong>扫描了大量的数据</strong>时，在 Buffer Pool 空间比较有限的情况下，可能会将 <strong>Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了</strong>，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 <strong>Buffer Pool 污染</strong>。</p><p>注意， Buffer Pool 污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成 Buffer Pool 污染。</p><p>比如，在一个数据量非常大的表，执行了这条语句：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#ff79c6>select</span> <span style=color:#ff79c6>*</span> <span style=color:#ff79c6>from</span> t_user <span style=color:#ff79c6>where</span> name <span style=color:#ff79c6>like</span> <span style=color:#f1fa8c>&#34;%xiaolin%&#34;</span>;
</span></span></code></pre></div><p>可能这个查询出来的结果就几条记录，但是由于这条语句会发生索引失效，所以这个查询过程是全表扫描的，接着会发生如下的过程：</p><ul><li>从磁盘读到的页加入到 LRU 链表的 old 区域头部；</li><li>当从页里读取行记录时，也就是页被访问的时候，就要将该页放到 young 区域头部；</li><li>接下来拿行记录的 name 字段和字符串 xiaolin 进行模糊匹配，如果符合条件，就加入到结果集里；</li><li>如此往复，直到扫描完表中的所有记录。</li></ul><p>经过这一番折腾，原本 young 区域的热点数据都会被替换掉。</p><p>举个例子，假设需要批量扫描：21，22，23，24，25 这五个页，这些页都会被逐一访问（读取页里的记录）。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/lruthree.drawio.png alt=img></p><p>在批量访问这些数据的时候，会被逐一插入到 young 区域头部。</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/lruthree1.png alt=img></p><p>可以看到，原本在 young 区域的热点数据 6 和 7 号页都被淘汰了，这就是 Buffer Pool 污染的问题。</p><blockquote><p>怎么解决出现 Buffer Pool 污染而导致缓存命中率下降的问题？</p></blockquote><p>像前面这种全表扫描的查询，很多缓冲页其实只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了。</p><p>LRU 链表中 young 区域就是热点数据，只要我们提高进入到 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换掉。</p><p>MySQL 是这样做的，进入到 young 区域条件增加了一个<strong>停留在 old 区域的时间判断</strong>。</p><p>具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：</p><ul><li>如果后续的访问时间与第一次访问的时间<strong>在某个时间间隔内</strong>，那么<strong>该缓存页就不会被从 old 区域移动到 young 区域的头部</strong>；</li><li>如果后续的访问时间与第一次访问的时间<strong>不在某个时间间隔内</strong>，那么<strong>该缓存页移动到 young 区域的头部</strong>；</li></ul><p>这个间隔时间是由 <code>innodb_old_blocks_time</code> 控制的，默认是 1000 ms。</p><p>也就说，<strong>只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部</strong>，这样就解决了 Buffer Pool 污染的问题 。</p><p>另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1/4 被访问不会移动到链表头部，只有后面的 3/4被访问了才会。</p><p><strong>4、脏页什么时候会被刷入磁盘？</strong></p><p>引入了 Buffer Pool 后，当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，但是磁盘中还是原数据。</p><p>因此，脏页需要被刷入磁盘，保证缓存和磁盘数据一致，但是若每次修改数据都刷入磁盘，则性能会很差，因此一般都会在一定时机进行批量刷盘。</p><p>可能大家担心，如果在脏页还没有来得及刷入到磁盘时，MySQL 宕机了，不就丢失数据了吗？</p><p>这个不用担心，InnoDB 的更新操作采用的是 Write Ahead Log 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。</p><p>下面几种情况会触发脏页的刷新：</p><ul><li>当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；</li><li>Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；</li><li>MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；</li><li>MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；</li></ul><p>在我们开启了慢 SQL 监控后，如果你发现**「偶尔」会出现一些用时稍长的 SQL**，这可能是因为脏页在刷新到磁盘时可能会给数据库带来性能开销，导致数据库操作抖动。</p><p>如果间断出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小</p><h1 id=mvcc>MVCC</h1><p>MVCC， 即多版本并发控制。MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p><h2 id=readview工作机制>ReadView工作机制</h2><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/readview%E7%BB%93%E6%9E%84.drawio.png alt=img></p><p>Read View 有四个重要的字段：</p><ul><li>m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，注意是一个列表，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li><li>min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li><li>max_trx_id ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li><li>creator_trx_id ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li></ul><p>知道了 Read View 的字段，我们还需要了解聚簇索引记录中的两个隐藏列。</p><p>假设在账户余额表插入一条小林余额为 100 万的记录，然后我把这两个隐藏列也画出来，该记录的整个示意图如下：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/f595d13450878acd04affa82731f76c5.png alt=图片></p><p>对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：</p><ul><li>trx_id，当一个事务对某条聚簇索引记录进行改动时，就会<strong>把该事务的事务 id 记录在 trx_id 隐藏列里</strong>；</li><li>roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 <strong>undo 日志</strong>中，然后<strong>这个隐藏列是个指针，指向每一个旧版本记录</strong>，于是就可以通过它找到修改前的记录。</li></ul><p>在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/%e4%ba%8b%e5%8a%a1%e9%9a%94%e7%a6%bb/ReadView.drawio.png alt=img></p><p>一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：</p><ul><li>如果记录的 trx_id 值小于 Read View 中的 <code>min_trx_id</code> 值，表示这个版本的记录是在创建 Read View <strong>前</strong>已经提交的事务生成的，所以该版本的记录对当前事务<strong>可见</strong>。</li><li>如果记录的 trx_id 值大于等于 Read View 中的 <code>max_trx_id</code> 值，表示这个版本的记录是在创建 Read View <strong>后</strong>才启动的事务生成的，所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id 值在 Read View 的min_trx_id和max_trx_id之间，需要判断 trx_id 是否在 m_ids 列表中：<ul><li>如果记录的 trx_id <strong>在</strong> <code>m_ids</code> 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id <strong>不在</strong> <code>m_ids</code>列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务<strong>可见</strong>。</li></ul></li></ul><p><strong>这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）</strong></p><h2 id=可重复读实现方式>可重复读实现方式</h2><p><strong>读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View</strong>。</p><p>也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</p><p>假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，接着按顺序执行了以下操作：</p><ul><li>事务 B 读取数据（创建 Read View），小林的账户余额为 100 万；</li><li>事务 A 修改数据（还没提交事务），将小林的账户余额从 100 万修改成了 200 万；</li><li>事务 B 读取数据（创建 Read View），小林的账户余额为 100 万；</li><li>事务 A 提交事务；</li><li>事务 B 读取数据（创建 Read View），小林的账户余额为 200 万；</li></ul><p>那具体怎么做到的呢？我们重点看事务 B 每次读取数据时创建的 Read View。前两次 事务 B 读取数据时创建的 Read View 如下图：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E8%AF%BB%E6%8F%90%E4%BA%A4%E4%BA%8B%E5%8A%A1.png alt=img></p><p>我们来分析下为什么事务 B 第二次读数据时，读不到事务 A （还未提交事务）修改的数据？</p><p>事务 B 在找到小林这条记录时，会看这条记录的 trx_id 是 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，接下来需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明<strong>这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录</strong>。而是，沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。</p><p>我们来分析下为什么事务 A 提交后，事务 B 就可以读到事务 A 修改的数据？</p><p>在事务 A 提交后，<strong>由于隔离级别是「读提交」，所以事务 B 在每次读数据的时候，会重新创建 Read View</strong>，此时事务 B 第三次读取数据时创建的 Read View 如下：</p><p><img src=https://raw.githubusercontent.com/lynnlee1229/PictureBed/main/%E8%AF%BB%E6%8F%90%E4%BA%A4%E4%BA%8B%E5%8A%A12.drawio.png alt=img></p><p>事务 B 在找到小林这条记录时，<strong>会发现这条记录的 trx_id 是 51，比事务 B 的 Read View 中的 min_trx_id 值（52）还小，这意味着修改这条记录的事务早就在创建 Read View 前提交过了，所以该版本的记录对事务 B 是可见的</strong>。</p><p>正是因为在读提交隔离级别下，事务每次读数据时都重新创建 Read View，那么在事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</p><h1 id=参考>参考：</h1><p><a href=https://pdai.tech/md/db/sql/sql-db-howitworks.html>https://pdai.tech/md/db/sql/sql-db-howitworks.html</a></p><p><a href=https://xiaolincoding.com/mysql/base/how_select.html#%E6%80%BB%E7%BB%93>https://xiaolincoding.com/mysql/base/how_select.html#%E6%80%BB%E7%BB%93</a>
<a href=https://www.javalearn.cn/#/doc/MySQL/%E9%9D%A2%E8%AF%95%E9%A2%98>https://www.javalearn.cn/#/doc/MySQL/%E9%9D%A2%E8%AF%95%E9%A2%98</a>
<a href=https://interviewguide.cn/notes/03-hunting_job/02-interview/04-01-01-MySQL.html>https://interviewguide.cn/notes/03-hunting_job/02-interview/04-01-01-MySQL.html</a></p><hr><ul class=pager><li class=previous><a href=/post/java%E5%85%AB%E8%82%A1-%E5%9F%BA%E7%A1%80/ data-toggle=tooltip data-placement=top title=【八股】java-基础>&larr;
Previous Post</a></li><li class=next><a href=/post/geomesa-%E7%AC%94%E8%AE%B0/ data-toggle=tooltip data-placement=top title=【笔记】geomesa-hbase>Next
Post &rarr;</a></li></ul></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/mysql%E5%85%AB%E8%82%A1 title=mysql八股>mysql八股</a>
<a href=/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1 title=数学建模>数学建模</a>
<a href=/tags/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB title=经验分享>经验分享</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://liebing.org.cn/>Liebing的博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:lizuolin1229@163.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/vx.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/lynnlee1229><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://www.linkedin.com/in/lynn-lee-4a6180237><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-linkedin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://www.instagram.com/lynn_lee_1229><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-instagram fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="Lynn's Site"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Lynn's Site 2023<br></p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){t=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),n=$(this).text(),i=$('<a href="'+o+'" rel="nofollow">'+n+"</a>"),s=$('<li class="'+t+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>